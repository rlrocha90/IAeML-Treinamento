{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Matriz de Confusão",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Importar dataset Mnist",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.datasets import fetch_openml\nimport numpy as np\n\nmnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\nmnist.target = mnist.target.astype(np.int8)\n\nX, y = mnist[\"data\"], mnist[\"target\"]\n\nnp.save('mnistX', X)\nnp.save('mnisty', y)\n\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\nshuffle_index = np.random.permutation(60000)\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n\ny_train_5 = (y_train == 5)\ny_test_5 = (y_test == 5)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Ajustando um classificador",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(loss='hinge', max_iter=5, tol=-np.infty, random_state=42)\nsgd_clf.fit(X_train, y_train_5)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Predição no conjunto de teste, sem Validação Cruzada",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_pred1 = sgd_clf.predict(X_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Predição no conjunto de teste, com Validação Cruzada",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score, cross_val_predict\n\nprint(\"Acurácia k-fold SGD: \")\nprint(cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\"))\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Matriz de Confusão",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nprint(\"Matriz de Confusão - treinamento com CrossValidation\")\nprint(confusion_matrix(y_train_5, y_train_pred))\nprint(ConfusionMatrixDisplay.from_estimator(sgd_clf, X_test, y_test_5))\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Uma matriz de confusão perfeita",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Matriz de confusão perfeita\")\nprint(confusion_matrix(y_train_5, y_train_5))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Métricas",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import precision_score, recall_score, f1_score\n\nprint(\"Precisão: \", precision_score(y_train_5, y_train_pred))\nprint(\"Recall: \", recall_score(y_train_5, y_train_pred))\nprint(\"F1-Score: \", f1_score(y_train_5, y_train_pred))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Verificação do Limiar para Recall x Precision",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "classe = 5 # Escolher uma classe\nenum = (y_test == classe)\ndig = np.where(enum == True)\ndigito = dig[0][1] # Alterar para ver as saídas\ny_scores = sgd_clf.decision_function([X_test[digito]])\nprint(y_scores)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "threshold = 0\ny_some_digit_pred = (y_scores > threshold)\nprint(\"É um 5?: \", y_some_digit_pred)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "threshold = 200000\ny_some_digit_pred = (y_scores > threshold)\nprint(\"É um 5?: \", y_some_digit_pred)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import precision_recall_curve\n\ny_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\nprecisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Definição de função para Precision x Limiar",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n    plt.xlabel(\"Threshold\", fontsize=16)\n    plt.legend(loc=\"upper left\", fontsize=16)\n    plt.ylim([0, 1])",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8, 4))\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.xlim([-700000, 700000])\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}