{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Gradiente MiniBatch",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nX = 2 * np.random.rand(100, 1)\ny = 4 + 3 * X + np.random.randn(100, 1)\n\nX_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance\nX_new = np.array([[0], [2]])\nX_new_b = np.c_[np.ones((2, 1)), X_new]  # add x0 = 1 to each instance\n\n\neta = 0.2\nn_iterations = 1000\nm = 100\ntheta = np.random.randn(2,1)\n\nfor iteration in range(n_iterations):\n    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n    theta = theta - eta * gradients\n\n\nprint(theta)\nX_new_b.dot(theta)\n\ntheta_path_bgd = []\n\n\ndef plot_gradient_descent(theta, eta, theta_path=None):\n    m = len(X_b)\n    plt.plot(X, y, \"b.\")\n    n_iterations = 1000\n    for iteration in range(n_iterations):\n        if iteration < 10: #testar outros valores para ver a evolução!!!\n            y_predict = X_new_b.dot(theta)\n            style = \"b-\" if iteration > 0 else \"r--\"\n            plt.plot(X_new, y_predict, style)\n        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n        theta = theta - eta * gradients\n        if theta_path is not None:\n            theta_path.append(theta)\n    plt.xlabel(\"$x_1$\", fontsize=14)\n    plt.axis([0, 2, 0, 15])\n    plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)\n    plt.show()\n\n\nnp.random.seed(42)\ntheta = np.random.randn(2, 1)  # random initialization\n\nplot_gradient_descent(theta, eta=0.02)\nplot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)\nplot_gradient_descent(theta, eta=0.5)\n\ntheta_path_sgd = []\nm = len(X_b)\nnp.random.seed(42)\n\nn_epochs = 50\nt0, t1 = 5, 50  # learning schedule hyperparameters\n\n\ndef learning_schedule(t):\n    return t0 / (t + t1)\n\n\ntheta = np.random.randn(2,1)  # random initialization\n\nfor epoch in range(n_epochs):\n    for i in range(m):\n        if epoch == 0 and i < 20:\n            y_predict = X_new_b.dot(theta)\n            style = \"b-\" if i > 0 else \"r--\"\n            plt.plot(X_new, y_predict, style)\n        random_index = np.random.randint(m)\n        xi = X_b[random_index:random_index+1]\n        yi = y[random_index:random_index+1]\n        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n        eta = learning_schedule(epoch * m + i)\n        theta = theta - eta * gradients\n        theta_path_sgd.append(theta)\n\n\ntheta_path_mgd = []\n\nn_iterations = 50\nminibatch_size = 60\n\nnp.random.seed(42)\ntheta = np.random.randn(2,1)  # random initialization\n\nt0, t1 = 200, 1000\n\n\ndef learning_schedule(t):\n    return t0 / (t + t1)\n\nt = 0\nfor epoch in range(n_iterations):\n    shuffled_indices = np.random.permutation(m)\n    X_b_shuffled = X_b[shuffled_indices]\n    y_shuffled = y[shuffled_indices]\n    for i in range(0, m, minibatch_size):\n        t += 1\n        xi = X_b_shuffled[i:i+minibatch_size]\n        yi = y_shuffled[i:i+minibatch_size]\n        gradients = 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n        eta = learning_schedule(t)\n        theta = theta - eta * gradients\n        theta_path_mgd.append(theta)\n\n\ntheta_path_bgd = np.array(theta_path_bgd)\ntheta_path_sgd = np.array(theta_path_sgd)\ntheta_path_mgd = np.array(theta_path_mgd)\n\nplt.figure(figsize=(7, 4))\nplt.plot(theta_path_sgd[:, 0], theta_path_sgd[:, 1], \"r-s\", linewidth=1, label=\"Stochastic\")\nplt.plot(theta_path_mgd[:, 0], theta_path_mgd[:, 1], \"g-+\", linewidth=2, label=\"Mini-batch\")\nplt.plot(theta_path_bgd[:, 0], theta_path_bgd[:, 1], \"b-o\", linewidth=3, label=\"Batch\")\nplt.legend(loc=\"upper left\", fontsize=16)\nplt.xlabel(r\"$\\theta_0$\", fontsize=14)\nplt.ylabel(r\"$\\theta_1$   \", fontsize=14, rotation=0)\nplt.axis([2.5, 4.5, 2.3, 3.9])\n\nplt.show()\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}