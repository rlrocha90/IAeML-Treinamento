{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Três Perceptron",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Dados e Tratamento",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nN = 1000\nseed = 8\nnp.random.seed(seed)\n\nx1 = np.random.randint(0,2,N, dtype=bool).reshape(N,1)\nx2 = np.random.randint(0,2,N, dtype=bool).reshape(N,1)\n\n# Função objetivo (Final desejado, XOR).\ny = x1 ^ x2\n\n# Labels do primeiro perceptron.\ny1 = x1 & (~x2)\n\n# Labels do segundo perceptron.\ny2 = (~x1) & x2\n\n# Atributos e labels do terceito perceptron.\nX3 = np.c_[y1, y2]\ny3 = y1 | y2\n\nx1 = x1 + 0.1*np.random.randn(N,1)\nx2 = x2 + 0.1*np.random.randn(N,1)\nX = np.c_[x1, x2]\n\nidx0 = np.argwhere(y.ravel() == 0)\nidx1 = np.argwhere(y.ravel() == 1)\n\nplt.plot(x1[idx0.ravel()], x2[idx0.ravel()], '.', label='Class 0')\nplt.plot(x1[idx1.ravel()], x2[idx1.ravel()], 'rx', label='Class 1')\nplt.xlabel('$x_1$', fontsize=14)\nplt.ylabel('$x_2$', fontsize=14)\nplt.title('Noisy XOR function')\nplt.legend()\nplt.show()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.3, random_state=seed)\nX1_train = np.c_[np.ones((len(y1_train), 1)), X1_train]\nX1_test = np.c_[np.ones((len(y1_test), 1)), X1_test]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Percpetrons",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Perceptron 1",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import Perceptron\nfrom sklearn.metrics import accuracy_score\n\nper1 = Perceptron(fit_intercept=False, random_state=seed)\nper1.fit(X1_train, y1_train.ravel())\ny_pred1 = per1.predict(X1_test)\nacc = accuracy_score(y1_test, y_pred1)\nprint('Acurácia perceptron #1:',acc)\n\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.3, random_state=seed)\nX2_train = np.c_[np.ones((len(y2_train), 1)), X2_train]\nX2_test = np.c_[np.ones((len(y2_test), 1)), X2_test]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Perceptron 2",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "per2 = Perceptron(fit_intercept=False, random_state=seed)\nper2.fit(X2_train, y2_train.ravel())\ny_pred2 = per2.predict(X2_test)\nacc = accuracy_score(y2_test, y_pred2)\nprint('Acurácia perceptron #2:',acc)\n\nX3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=seed)\nX3_train = np.c_[np.ones((len(y3_train), 1)), X3_train]\nX3_test = np.c_[np.ones((len(y3_test), 1)), X3_test]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Perceptron 3",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "per3 = Perceptron(fit_intercept=False, random_state=seed)\nper3.fit(X3_train, y3_train.ravel())\ny_pred3 = per3.predict(X3_test)\nacc = accuracy_score(y3_test, y_pred3)\nprint('Acurácia perceptron #3:',acc)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Definição de uma classe para Classificador",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class Classifier():\n\n    def __init__(self, per1, per2, per3):\n        self.per1 = per1\n        self.per2 = per2\n        self.per3 = per3\n\n    def predict(self, X):\n        N = X.shape[0]  # get the number of lines.\n        y1 = self.per1.predict(X).reshape(N, 1)\n        y2 = self.per2.predict(X).reshape(N, 1)\n        X3 = np.c_[np.ones((len(y1), 1)), y1, y2]\n        y3 = self.per3.predict(X3)\n        return y3",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Instanciando o Classificador",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "clf = Classifier(per1, per2, per3)\nX_ = np.c_[np.ones((N,1)), X]\ny_pred = clf.predict(X_)\n\nacc = accuracy_score(y, y_pred)\nprint('Acurácia da combinação dos 3 perceptrons:',acc)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Saídas",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\nh = .01\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\nattribute_matrix = np.c_[np.ones((len(xx.ravel()), 1)), xx.ravel(), yy.ravel()]\nZ = clf.predict(attribute_matrix)\nZ = Z.reshape(xx.shape)\nplt.pcolormesh(xx, yy, Z, cmap=plt.cm.Greens, shading='auto')\n\nplt.plot(X[idx0,0], X[idx0,1], '.', markersize=8, label='Class 0')\nplt.plot(X[idx1,0], X[idx1,1], 'rx', markersize=8, label='Class 1')\nplt.xlabel('$x_1$', fontsize=14)\nplt.ylabel('$x_2$', fontsize=14)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.show()\n\nX_test = np.c_[np.ones((len(y_test), 1)), X_test]\ny_pred = clf.predict(X_test)\n\nmat = confusion_matrix(y_test, y_pred)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels=range(2), yticklabels=range(2), cmap=\"Blues\")\nplt.xlabel('true label')\nplt.ylabel('predicted label')\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}